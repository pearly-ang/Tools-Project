{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SYNGENTA CROP CHALLENGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to predict crop yield"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The challenge is to understand and classify crop yield based on two set of environmental features; heat and drought. We have modelled both separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and exploring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "performance_data = pd.read_csv('performance_data.csv')\n",
    "submission_template = pd.read_csv('submission_template.csv')\n",
    "weather_data = pd.read_csv('weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HYBRID_ID</th>\n",
       "      <th>ENV_ID</th>\n",
       "      <th>HYBRID_MG</th>\n",
       "      <th>ENV_MG</th>\n",
       "      <th>YIELD</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LONG</th>\n",
       "      <th>PLANT_DATE</th>\n",
       "      <th>HARVEST_DATE</th>\n",
       "      <th>...</th>\n",
       "      <th>ENV_YIELD_STD</th>\n",
       "      <th>ELEVATION</th>\n",
       "      <th>CLAY</th>\n",
       "      <th>SILT</th>\n",
       "      <th>SAND</th>\n",
       "      <th>AWC</th>\n",
       "      <th>PH</th>\n",
       "      <th>OM</th>\n",
       "      <th>CEC</th>\n",
       "      <th>KSAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>H2782</td>\n",
       "      <td>Env_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>107.9577</td>\n",
       "      <td>2008</td>\n",
       "      <td>49.5</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2008-05-06</td>\n",
       "      <td>2008-11-03</td>\n",
       "      <td>...</td>\n",
       "      <td>7.591866</td>\n",
       "      <td>870.65</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.0</td>\n",
       "      <td>54.5</td>\n",
       "      <td>18.65</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H2782</td>\n",
       "      <td>Env_2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.7498</td>\n",
       "      <td>2008</td>\n",
       "      <td>49.3</td>\n",
       "      <td>-98.1</td>\n",
       "      <td>2008-05-14</td>\n",
       "      <td>2008-10-22</td>\n",
       "      <td>...</td>\n",
       "      <td>7.184953</td>\n",
       "      <td>942.41</td>\n",
       "      <td>22.7</td>\n",
       "      <td>22.0</td>\n",
       "      <td>55.8</td>\n",
       "      <td>18.75</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>25.2</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H2240</td>\n",
       "      <td>Env_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.6116</td>\n",
       "      <td>2011</td>\n",
       "      <td>49.3</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2011-05-17</td>\n",
       "      <td>2011-10-17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.583234</td>\n",
       "      <td>903.46</td>\n",
       "      <td>22.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>18.95</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>25.5</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H1527</td>\n",
       "      <td>Env_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.8191</td>\n",
       "      <td>2011</td>\n",
       "      <td>49.3</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2011-05-17</td>\n",
       "      <td>2011-10-17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.583234</td>\n",
       "      <td>903.46</td>\n",
       "      <td>22.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>18.95</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>25.5</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H1369</td>\n",
       "      <td>Env_3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.7917</td>\n",
       "      <td>2011</td>\n",
       "      <td>49.3</td>\n",
       "      <td>-98.0</td>\n",
       "      <td>2011-05-17</td>\n",
       "      <td>2011-10-17</td>\n",
       "      <td>...</td>\n",
       "      <td>4.583234</td>\n",
       "      <td>903.46</td>\n",
       "      <td>22.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>18.95</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>25.5</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  HYBRID_ID ENV_ID  HYBRID_MG  ENV_MG     YIELD  YEAR   LAT  LONG  PLANT_DATE  \\\n",
       "0     H2782  Env_1          0       0  107.9577  2008  49.5 -98.0  2008-05-06   \n",
       "1     H2782  Env_2          0       0   85.7498  2008  49.3 -98.1  2008-05-14   \n",
       "2     H2240  Env_3          0       0   74.6116  2011  49.3 -98.0  2011-05-17   \n",
       "3     H1527  Env_3          0       0   83.8191  2011  49.3 -98.0  2011-05-17   \n",
       "4     H1369  Env_3          0       0   81.7917  2011  49.3 -98.0  2011-05-17   \n",
       "\n",
       "  HARVEST_DATE  ...  ENV_YIELD_STD  ELEVATION  CLAY  SILT  SAND    AWC   PH  \\\n",
       "0   2008-11-03  ...       7.591866     870.65  22.7  23.0  54.5  18.65  7.2   \n",
       "1   2008-10-22  ...       7.184953     942.41  22.7  22.0  55.8  18.75  7.3   \n",
       "2   2011-10-17  ...       4.583234     903.46  22.8  21.5  55.8  18.95  7.4   \n",
       "3   2011-10-17  ...       4.583234     903.46  22.8  21.5  55.8  18.95  7.4   \n",
       "4   2011-10-17  ...       4.583234     903.46  22.8  21.5  55.8  18.95  7.4   \n",
       "\n",
       "    OM   CEC  KSAT  \n",
       "0  6.1  24.2   9.4  \n",
       "1  6.9  25.2  10.2  \n",
       "2  6.7  25.5   9.9  \n",
       "3  6.7  25.5   9.9  \n",
       "4  6.7  25.5   9.9  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming weather data into useful metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environmental data will be grouped by ENV_ID. Both averages and standard deviations will be obtained so as to capture the differences in weather. NB: Same average temperatures can hide different extreme environments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYL_AVG</th>\n",
       "      <th>PREC_AVG</th>\n",
       "      <th>SRAD_AVG</th>\n",
       "      <th>SWE_AVG</th>\n",
       "      <th>TMAX_AVG</th>\n",
       "      <th>TMIN_AVG</th>\n",
       "      <th>VP_AVG</th>\n",
       "      <th>DAY_NUM_STD</th>\n",
       "      <th>DAYL_STD</th>\n",
       "      <th>PREC_STD</th>\n",
       "      <th>SRAD_STD</th>\n",
       "      <th>SWE_STD</th>\n",
       "      <th>TMAX_STD</th>\n",
       "      <th>TMIN_STD</th>\n",
       "      <th>VP_STD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENV_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Env_1</th>\n",
       "      <td>43200.000043</td>\n",
       "      <td>1.684932</td>\n",
       "      <td>276.111781</td>\n",
       "      <td>11.167123</td>\n",
       "      <td>8.093151</td>\n",
       "      <td>-3.256164</td>\n",
       "      <td>630.356164</td>\n",
       "      <td>105.510663</td>\n",
       "      <td>10075.200862</td>\n",
       "      <td>4.544882</td>\n",
       "      <td>131.085275</td>\n",
       "      <td>16.046875</td>\n",
       "      <td>14.926959</td>\n",
       "      <td>13.574307</td>\n",
       "      <td>535.634711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Env_10</th>\n",
       "      <td>43200.946768</td>\n",
       "      <td>3.079452</td>\n",
       "      <td>294.978630</td>\n",
       "      <td>19.868493</td>\n",
       "      <td>12.095890</td>\n",
       "      <td>2.241096</td>\n",
       "      <td>874.191781</td>\n",
       "      <td>105.510663</td>\n",
       "      <td>8183.382184</td>\n",
       "      <td>5.974924</td>\n",
       "      <td>134.977729</td>\n",
       "      <td>31.810984</td>\n",
       "      <td>11.625704</td>\n",
       "      <td>9.839269</td>\n",
       "      <td>559.526111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Env_100</th>\n",
       "      <td>43200.000070</td>\n",
       "      <td>2.901370</td>\n",
       "      <td>296.714521</td>\n",
       "      <td>20.679452</td>\n",
       "      <td>12.616438</td>\n",
       "      <td>0.632877</td>\n",
       "      <td>820.054795</td>\n",
       "      <td>105.510663</td>\n",
       "      <td>8795.413435</td>\n",
       "      <td>7.152662</td>\n",
       "      <td>119.593751</td>\n",
       "      <td>30.413609</td>\n",
       "      <td>12.877466</td>\n",
       "      <td>12.410814</td>\n",
       "      <td>614.102577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Env_1000</th>\n",
       "      <td>43200.946854</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>352.368219</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>18.323288</td>\n",
       "      <td>2.883562</td>\n",
       "      <td>824.876712</td>\n",
       "      <td>105.510663</td>\n",
       "      <td>6955.702533</td>\n",
       "      <td>6.970897</td>\n",
       "      <td>111.010912</td>\n",
       "      <td>2.447805</td>\n",
       "      <td>11.374718</td>\n",
       "      <td>10.219944</td>\n",
       "      <td>674.104452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Env_1001</th>\n",
       "      <td>43200.946854</td>\n",
       "      <td>2.561644</td>\n",
       "      <td>341.681097</td>\n",
       "      <td>2.443836</td>\n",
       "      <td>17.701370</td>\n",
       "      <td>2.924658</td>\n",
       "      <td>862.246575</td>\n",
       "      <td>105.510663</td>\n",
       "      <td>6955.702533</td>\n",
       "      <td>8.697269</td>\n",
       "      <td>112.386846</td>\n",
       "      <td>5.729262</td>\n",
       "      <td>11.039508</td>\n",
       "      <td>10.119774</td>\n",
       "      <td>629.404388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              DAYL_AVG  PREC_AVG    SRAD_AVG    SWE_AVG   TMAX_AVG  TMIN_AVG  \\\n",
       "ENV_ID                                                                         \n",
       "Env_1     43200.000043  1.684932  276.111781  11.167123   8.093151 -3.256164   \n",
       "Env_10    43200.946768  3.079452  294.978630  19.868493  12.095890  2.241096   \n",
       "Env_100   43200.000070  2.901370  296.714521  20.679452  12.616438  0.632877   \n",
       "Env_1000  43200.946854  2.000000  352.368219   0.997260  18.323288  2.883562   \n",
       "Env_1001  43200.946854  2.561644  341.681097   2.443836  17.701370  2.924658   \n",
       "\n",
       "              VP_AVG  DAY_NUM_STD      DAYL_STD  PREC_STD    SRAD_STD  \\\n",
       "ENV_ID                                                                  \n",
       "Env_1     630.356164   105.510663  10075.200862  4.544882  131.085275   \n",
       "Env_10    874.191781   105.510663   8183.382184  5.974924  134.977729   \n",
       "Env_100   820.054795   105.510663   8795.413435  7.152662  119.593751   \n",
       "Env_1000  824.876712   105.510663   6955.702533  6.970897  111.010912   \n",
       "Env_1001  862.246575   105.510663   6955.702533  8.697269  112.386846   \n",
       "\n",
       "            SWE_STD   TMAX_STD   TMIN_STD      VP_STD  \n",
       "ENV_ID                                                 \n",
       "Env_1     16.046875  14.926959  13.574307  535.634711  \n",
       "Env_10    31.810984  11.625704   9.839269  559.526111  \n",
       "Env_100   30.413609  12.877466  12.410814  614.102577  \n",
       "Env_1000   2.447805  11.374718  10.219944  674.104452  \n",
       "Env_1001   5.729262  11.039508  10.119774  629.404388  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group data by crop id\n",
    "weather_data_grouped_mean = weather_data.groupby(by='ENV_ID').mean()\n",
    "weather_data_grouped_std = weather_data.groupby(by='ENV_ID').std()\n",
    "weather_data_grouped = weather_data_grouped_mean.join(weather_data_grouped_std,\n",
    "                                                      lsuffix='_AVG',\n",
    "                                                     rsuffix='_STD')\n",
    "weather_data_grouped = weather_data_grouped.drop('DAY_NUM_AVG',axis=1)\n",
    "weather_data_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4b5c1fbfa361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mperformance_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ENV_ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6334\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6335\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 6336\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   6337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6349\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   6350\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6351\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   6352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             elif (not is_numeric_dtype(lk)\n\u001b[1;32m    985\u001b[0m                     and (is_numeric_dtype(rk) and not is_bool_dtype(rk))):\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "performance_data.head()\n",
    "joined_df = performance_data.join(weather_data,on='ENV_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-72b9355b70fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Joining performance and weather data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ENV_ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mjoined_df_grouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperformance_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_data_grouped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ENV_ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mjoined_df_grouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6334\u001b[0m         \u001b[0;31m# For SparseDataFrame's benefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6335\u001b[0m         return self._join_compat(other, on=on, how=how, lsuffix=lsuffix,\n\u001b[0;32m-> 6336\u001b[0;31m                                  rsuffix=rsuffix, sort=sort)\n\u001b[0m\u001b[1;32m   6337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6338\u001b[0m     def _join_compat(self, other, on=None, how='left', lsuffix='', rsuffix='',\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[1;32m   6349\u001b[0m             return merge(self, other, left_on=on, how=how,\n\u001b[1;32m   6350\u001b[0m                          \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6351\u001b[0;31m                          suffixes=(lsuffix, rsuffix), sort=sort)\n\u001b[0m\u001b[1;32m   6352\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     59\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    984\u001b[0m             elif (not is_numeric_dtype(lk)\n\u001b[1;32m    985\u001b[0m                     and (is_numeric_dtype(rk) and not is_bool_dtype(rk))):\n\u001b[0;32m--> 986\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "## Joining performance and weather data\n",
    "joined_df = performance_data.join(weather_data,on='ENV_ID')\n",
    "joined_df_grouped = performance_data.join(weather_data_grouped,on='ENV_ID')\n",
    "joined_df_grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discerning between heat and drought varibles\n",
    "heat_stress_df = joined_df_grouped[['HYBRID_ID','ENV_ID','TMAX_AVG','TMAX_STD',\n",
    "                            'TMIN_AVG','TMIN_STD','DAYL_AVG','DAYL_STD',\n",
    "                           'SRAD_AVG','SRAD_STD','YIELD']]\n",
    "drought_stress_df = joined_df_grouped[['HYBRID_ID','ENV_ID','IRRIGATION','PREC_AVG','PREC_STD','KSAT',\n",
    "                              'SWE_AVG','SWE_STD','VP_AVG','VP_STD','AWC','YIELD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_df = joined_df[['LONG', 'LAT', 'PREC', 'TMAX', 'TMIN']].drop_duplicates()\n",
    "#determine min, mean, max\n",
    "#segment factor from 1 to 4\n",
    "\n",
    "def factor_seg(df, factor):\n",
    "    min_ = factor_df[factor].min()\n",
    "    max_ = factor_df[factor].max()\n",
    "    mean_ = factor_df[factor].mean()\n",
    "    #binning\n",
    "    diff = (max_ - min_)/4\n",
    "    b_l = list()\n",
    "    for x in range(len(df)):\n",
    "        temp = 0\n",
    "        if df.iloc[x][factor] < (min_ + diff):\n",
    "            temp = 1\n",
    "        elif df.iloc[x][factor] < (min_ + 2*diff):\n",
    "            temp = 2\n",
    "        elif df.iloc[x][factor] < (min_ + 3*diff):\n",
    "            temp = 3\n",
    "        else:\n",
    "            temp = 4\n",
    "        b_l.append(temp)\n",
    "    df.insert(loc=0, column=factor + '_binning', value=b_l)\n",
    "    return df\n",
    "test_df = factor_seg(factor_df, 'PREC')\n",
    "#test_df\n",
    "#test_df.loc[:, 'PREC_binning']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folium map with popup markers for every coordinate pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folium map\n",
    "#For every coordinate pair: a popup shows values for 'PREC', 'IRR', 'ELEVATION', 'TMAX', 'TMIN'\n",
    "import folium\n",
    "m = folium.Map(location=[39, -96], zoom_start=5, tiles='Stamen Terrain')\n",
    "folium_data = joined_df[['LONG', 'LAT', 'PREC','IRRIGATION', 'ELEVATION', 'TMAX', 'TMIN']].drop_duplicates()\n",
    "folium\n",
    "for x in range(len(folium_data)):\n",
    "    folium.Marker([folium_data.iloc[x]['LAT'], folium_data.iloc[x]['LONG']], popup=(f\"\"\"Prec: {folium_data.iloc[x]['PREC']:.2f} IRR: {folium_data.iloc[x]['IRRIGATION']} Elev: {folium_data.iloc[x]['ELEVATION']:.0f} Tmax: {folium_data.iloc[x]['TMAX']:.2f} Tmin: {folium_data.iloc[x]['TMIN']:.2f}\"\"\")).add_to(m)\n",
    "m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation heatmap\n",
    "There are no strong correlations between weather conditions and yield if we look at the aggregated data. We can conclude we'll have to go one level deeper and do the analysis on every specific Hybrid_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Prepare dataframe to redo correlation matrix\n",
    "joined_df_drop = joined_df.drop(['HYBRID_ID','ENV_ID','ENV_YIELD_MEAN','ENV_YIELD_STD'],axis='columns')\n",
    "corr_matrix_joined = joined_df_drop.corr()\n",
    "\n",
    "# Draw heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix_joined,cmap='BuGn')\n",
    "top_5 = corr_matrix_joined['YIELD'].sort_values(ascending=False).iloc[1:6]\n",
    "bottom_5 = corr_matrix_joined['YIELD'].sort_values(ascending=True).iloc[0:5]\n",
    "print(top_5,bottom_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heat stress variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat stress variables to yield correlation\n",
    "# Import modules\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Prepare dataframe to redo correlation matrix\n",
    "heat_stress_df_drop = heat_stress_df.drop(['HYBRID_ID','ENV_ID','ENV_YIELD_MEAN','ENV_YIELD_STD'],axis='columns')\n",
    "corr_matrix_heat = heat_stress_df_drop.corr()\n",
    "\n",
    "# Draw heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix_heat,cmap='YlOrRd')\n",
    "\n",
    "print(corr_matrix_heat['YIELD'].sort_values(ascending=False))\n",
    "#corr_matrix_heat['YIELD'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_stress_features_list = ['TMAX_AVG','DAYL_AVG','SRAD_AVG', 'TMAX_STD', 'DAYL_STD','SRAD_STD']\n",
    "\n",
    "#heat_stress_df_drop = df[heat_stress_features_list]\n",
    "#heat_stress_features = [x for x in heat_stress_features_list]\n",
    "\n",
    "fig, ax = plt.subplots(round(len(heat_stress_features_list) / 3), 3, figsize = (18, 12))\n",
    "\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    if i < len(heat_stress_features_list) - 1:\n",
    "        sns.regplot(x=heat_stress_features_list[i],y='YIELD', data=heat_stress_df_drop, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drought stress variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drought stress variables to yield correlation\n",
    "# Import modules\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Prepare dataframe to redo correlation matrix\n",
    "drought_stress_df_drop = drought_stress_df.drop(['HYBRID_ID','ENV_ID','ENV_YIELD_MEAN','ENV_YIELD_STD'],axis='columns')\n",
    "corr_matrix_drought = drought_stress_df_drop.corr()\n",
    "\n",
    "# Draw heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(12,10))\n",
    "sns.heatmap(corr_matrix_heat,cmap='YlGnBu')\n",
    "\n",
    "print(corr_matrix_drought['YIELD'].sort_values(ascending=False))\n",
    "#corr_matrix_drought['YIELD'].sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between each drought variable and yield\n",
    "drought_stress_features_list = ['PREC_STD','VP_STD','AWC', 'PREC_AVG','VP_AVG','KSAT','SWE_STD','SWE_AVG']\n",
    "\n",
    "fig, ax = plt.subplots(round(len(drought_stress_features_list) / 3), 3, figsize = (18, 12))\n",
    "\n",
    "for i, ax in enumerate(fig.axes):\n",
    "    if i < len(drought_stress_features_list) - 1:\n",
    "        sns.regplot(x=drought_stress_features_list[i],y='YIELD', data=drought_stress_df_drop, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring categorical variables\n",
    "- Captures non-numeric variable not featured in the correlation matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordered from least to most irrigated \n",
    "var = 'IRRIGATION'\n",
    "data = pd.concat([joined_df['YIELD'], joined_df[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"YIELD\", data=data, order=[\"NONE\", \"DRY\", \"ECO\",\"LIRR\",\"IRR\"])\n",
    "fig.axis(ymin=0, ymax=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same for PREC\n",
    "var = 'IRRIGATION'\n",
    "data = pd.concat([joined_df['PREC_AVG'], joined_df[var]], axis=1)\n",
    "f, ax = plt.subplots(figsize=(8, 6))\n",
    "fig = sns.boxplot(x=var, y=\"PREC_AVG\", data=data, order=[\"NONE\", \"DRY\", \"ECO\",\"LIRR\",\"IRR\"])\n",
    "fig.axis(ymin=0, ymax=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HEAT STRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting non-numeric variables to index\n",
    "heat_stress_df = heat_stress_df.set_index(['HYBRID_ID','ENV_ID'])\n",
    "heat_stress_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total performance observations: ' + str(len(heat_stress_df)))\n",
    "print('Total unique hybrids: ' + str(len(heat_stress_df.reset_index()['HYBRID_ID'].unique())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training (70%), testing (20%) and validation (10%)\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(heat_stress_df, test_size = 0.1, random_state=1)\n",
    "x_train = train.iloc[:,0:-1]\n",
    "y_train = train['YIELD']\n",
    "x_test = test.iloc[:,0:-1]\n",
    "y_test = test['YIELD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "\n",
    "tree_model_hs = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Fitting models\n",
    "tree_model_hs.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get score on the testing data\n",
    "print('Model score equals: %.3f' % tree_model_hs.score(x_test,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the underlying parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key parameter in the Decision Tree Regressor is the minimum number of instances, i.e. the minimum number of samples required to be at a leaf node. We would expect the model to reduce its MSE to the training data when we decrease the minimum samples required to be a leaf node because more nodes would be added and the data would be more \"fit\" to the training data. However, with such procedure we would be exposed to an overfitting risk of the model to the training data and hence our MSE to the testing data would increase. \n",
    "\n",
    "Surprisingly, the figure below shows this does not apply in our case. The lower the number of instances required in a leaf node, the better for both the training and testing data. We can conclude that having a \"super-tree\" with as much leafes as number of instances is the best approach for both the training and testing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax0 = fig.add_subplot(111) \n",
    "RMSE_train = []\n",
    "RMSE_test = []\n",
    "iterations = 100\n",
    "\n",
    "for i in range(1,iterations):\n",
    "    #Parametrize the model and let i be the number of minimum instances per leaf node\n",
    "    regression_model = tree.DecisionTreeRegressor(criterion=\"mse\",min_samples_leaf=i)   \n",
    "    #Train the model\n",
    "    regression_model.fit(x_train,y_train)\n",
    "    #Predict query instances\n",
    "    predicted_train = regression_model.predict(x_train)\n",
    "    predicted_test = regression_model.predict(x_test)\n",
    "    #Calculate and append the RMSEs\n",
    "    RMSE_train.append(np.sqrt(np.sum(((y_train-predicted_train)**2)/len(y_train))))\n",
    "    RMSE_test.append(np.sqrt(np.sum(((y_test-predicted_test)**2)/len(y_test))))\n",
    "    \n",
    "ax0.plot(range(1,iterations),RMSE_test,label='Test_Data')\n",
    "ax0.plot(range(1,iterations),RMSE_train,label='Train_Data')\n",
    "ax0.legend()\n",
    "ax0.set_title('RMSE with respect to the minumim number of instances per node')\n",
    "ax0.set_xlabel('#Instances')\n",
    "ax0.set_ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same perspective but with model scores (ranging from 0 to 1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax0 = fig.add_subplot(111) \n",
    "SCORE_train = []\n",
    "SCORE_test = []\n",
    "iterations = 100\n",
    "\n",
    "for i in range(1,iterations):\n",
    "    #Parametrize the model and let i be the number of minimum instances per leaf node\n",
    "    regression_model = tree.DecisionTreeRegressor(criterion=\"mse\",min_samples_leaf=i)   \n",
    "    #Train the model\n",
    "    regression_model.fit(x_train,y_train)\n",
    "    #Get scores\n",
    "    SCORE_train.append(regression_model.score(x_train,y_train))\n",
    "    SCORE_test.append(regression_model.score(x_test,y_test))\n",
    "        \n",
    "ax0.plot(range(1,iterations),SCORE_test,label='Test_Data')\n",
    "ax0.plot(range(1,iterations),SCORE_train,label='Train_Data')\n",
    "ax0.legend()\n",
    "ax0.set_title('SCORE with respect to the minumim number of instances per node')\n",
    "ax0.set_xlabel('#Instances')\n",
    "ax0.set_ylabel('SCORE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree illustration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DAYL_STD is the most decisive factor when it comes to predicting yield\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image\n",
    "\n",
    "feature_names = [key for key in heat_stress_df.columns if not key == 'YIELD']\n",
    "\n",
    "dot_data = tree.export_graphviz(tree_model_hs,\n",
    "                                max_depth=2,\n",
    "                                out_file=None,\n",
    "                                feature_names=feature_names)\n",
    "\n",
    "graph = pydotplus.graphviz.graph_from_dot_data(dot_data)\n",
    "\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importances and individual scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discerning feature importances\n",
    "tree_model_hs.feature_importances_\n",
    "\n",
    "# Normalizing dataframe\n",
    "norm_hs = sklearn.preprocessing.normalize(heat_stress_df,axis=0)\n",
    "df_hs = pd.DataFrame(norm_hs)\n",
    "df_hs.describe()\n",
    "heat_stress_df.describe()\n",
    "norm_hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DROUGHT STRESS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting non-numeric variables to index\n",
    "drought_stress_df = drought_stress_df.set_index(['HYBRID_ID','ENV_ID'])\n",
    "drought_stress_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting irrigation to numeric values\n",
    "def irrigation_converter(string):\n",
    "    import numpy as np\n",
    "    if string == np.nan:\n",
    "        return np.nan\n",
    "    if string == 'NONE' or string == 'DRY':\n",
    "        return 0\n",
    "    if string == 'ECO':\n",
    "        return 1\n",
    "    if string == 'LIRR':\n",
    "        return 2\n",
    "    if string == 'IRR':\n",
    "        return 3\n",
    "    else:\n",
    "        next\n",
    "\n",
    "drought_stress_df['IRRIGATION'] = drought_stress_df['IRRIGATION'].apply(irrigation_converter)\n",
    "print('Total performance observations: ' + str(len(drought_stress_df)))\n",
    "print('Total unique hybrids: ' + str(len(drought_stress_df.reset_index()['HYBRID_ID'].unique())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan\n",
    "drought_stress_df.dropna(inplace=True)\n",
    "\n",
    "print('Total performance observations: ' + str(len(drought_stress_df)))\n",
    "print('Total unique hybrids: ' + str(len(drought_stress_df.reset_index()['HYBRID_ID'].unique())))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up a Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(drought_stress_df, test_size = 0.3, random_state=1)\n",
    "x_train = train.iloc[:,0:-1]\n",
    "y_train = train['YIELD']\n",
    "x_test = test.iloc[:,0:-1]\n",
    "y_test = test['YIELD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up model\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "\n",
    "tree_model_ds = tree.DecisionTreeRegressor()\n",
    "\n",
    "# Fitting models\n",
    "tree_model_ds.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get score on the testing data\n",
    "print(tree_model_ds.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree illustration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IRRIGATION is the most decisive factor when it comes to predicting yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus \n",
    "from IPython.display import Image\n",
    "\n",
    "feature_names = [key for key in drought_stress_df.columns if not key == 'YIELD']\n",
    "\n",
    "dot_data = tree.export_graphviz(tree_model_ds,\n",
    "                                max_depth=2,\n",
    "                                out_file=None,\n",
    "                                feature_names=feature_names)\n",
    "\n",
    "graph = pydotplus.graphviz.graph_from_dot_data(dot_data)\n",
    "\n",
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
